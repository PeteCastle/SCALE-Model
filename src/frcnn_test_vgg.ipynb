{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UauKNtFRqydu"
      },
      "source": [
        "### Import libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "qSbY3Amlqpkh",
        "outputId": "785ace30-0652-460a-f5b7-2f6a877ad6ee"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import pickle\n",
        "\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers import Input\n",
        "\n",
        "\n",
        "\n",
        "# from layers.base import nn_base\n",
        "# from layers.rpn import rpn_layer\n",
        "# from layers.classifier import classifier_layer\n",
        "# from layers.calculations import apply_regr, non_max_suppression_fast, rpn_to_roi\n",
        "\n",
        "# from utils.images import format_img\n",
        "# from utils.functions import get_data\n",
        "# from utils.images import get_real_coordinates\n",
        "# from utils.iou import iou\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "print(tf.config.list_physical_devices())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C66bqGuOq7w6"
      },
      "outputs": [],
      "source": [
        "base_path = 'data'\n",
        "\n",
        "test_path = 'data/test_data_annotations.csv' # Test data (annotation file)\n",
        "\n",
        "test_base_path = 'data/test/' # Directory to save the test images\n",
        "\n",
        "config_output_filename = os.path.join(base_path, 'model_vgg_config.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Hr7saGnTxC0S"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data\\\\model_vgg_config.pickle'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_output_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f_in:\n\u001b[0;32m      2\u001b[0m \tC \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f_in)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# turn off any data augmentation at test time\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Miniconda3\\envs\\mosquito_env_training\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\model_vgg_config.pickle'"
          ]
        }
      ],
      "source": [
        "with open(config_output_filename, 'rb') as f_in:\n",
        "\tC = pickle.load(f_in)\n",
        "\n",
        "# turn off any data augmentation at test time\n",
        "\n",
        "C.use_horizontal_flips = False\n",
        "C.use_vertical_flips = False\n",
        "C.rot_90 = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1289
        },
        "colab_type": "code",
        "id": "Kt-1Grs90oD3",
        "outputId": "e3bac09d-be95-4a1c-cae3-9b82fe82ed07"
      },
      "outputs": [],
      "source": [
        "# Load the records\n",
        "record_df = pd.read_csv(C.record_path)\n",
        "\n",
        "r_epochs = len(record_df)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n",
        "plt.title('mean_overlapping_bboxes')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n",
        "plt.title('class_acc')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n",
        "plt.title('loss_rpn_cls')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n",
        "plt.title('loss_rpn_regr')\n",
        "plt.show()\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
        "plt.title('loss_class_cls')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n",
        "plt.title('loss_class_regr')\n",
        "plt.show()\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
        "plt.title('total_loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['elapsed_time'], 'r')\n",
        "plt.title('elapsed_time')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SJTc51uyFrKc"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "yLrF_sMQIRPR",
        "outputId": "e0b5b6a9-fb88-4f43-d6e3-5f028d287fc8"
      },
      "outputs": [],
      "source": [
        "num_features = 512\n",
        "\n",
        "input_shape_img = (None, None, 3)\n",
        "input_shape_features = (None, None, num_features)\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(C.num_rois, 4))\n",
        "feature_map_input = Input(shape=input_shape_features)\n",
        "\n",
        "# define the base network (VGG here, can be Resnet50, Inception, etc)\n",
        "shared_layers = nn_base(img_input, trainable=True)\n",
        "\n",
        "# define the RPN, built on the base layers\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
        "rpn_layers = rpn_layer(shared_layers, num_anchors)\n",
        "\n",
        "classifier = classifier_layer(feature_map_input, roi_input, C.num_rois, nb_classes=len(C.class_mapping))\n",
        "\n",
        "model_rpn = Model(img_input, rpn_layers)\n",
        "model_classifier_only = Model([feature_map_input, roi_input], classifier)\n",
        "\n",
        "model_classifier = Model([feature_map_input, roi_input], classifier)\n",
        "\n",
        "print('Loading weights from {}'.format(C.model_path))\n",
        "model_rpn.load_weights(C.model_path, by_name=True)\n",
        "model_classifier.load_weights(C.model_path, by_name=True)\n",
        "\n",
        "model_rpn.compile(optimizer='sgd', loss='mse')\n",
        "model_classifier.compile(optimizer='sgd', loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "oMGXOYQbK_Rx",
        "outputId": "4a3f7d6a-7af5-4efe-cffd-4b6c9c1f3c85"
      },
      "outputs": [],
      "source": [
        "# Switch key value for class mapping\n",
        "class_mapping = C.class_mapping\n",
        "class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "print(class_mapping)\n",
        "class_to_color = {class_mapping[v]: np.random.randint(0, 255, 3) for v in class_mapping}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cX5OTM5Ppl0W"
      },
      "outputs": [],
      "source": [
        "test_imgs = os.listdir(test_base_path)\n",
        "\n",
        "imgs_path = []\n",
        "for i in range(12):\n",
        "\tidx = np.random.randint(len(test_imgs))\n",
        "\timgs_path.append(test_imgs[idx])\n",
        "\n",
        "all_imgs = []\n",
        "\n",
        "classes = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5818
        },
        "colab_type": "code",
        "id": "lChm3e9WIijw",
        "outputId": "f8fa8e83-83e3-45ea-83a1-61402e4157c1"
      },
      "outputs": [],
      "source": [
        "# If the box classification value is less than this, we ignore this box\n",
        "bbox_threshold = 0.9\n",
        "\n",
        "\n",
        "for idx, img_name in enumerate(imgs_path):\n",
        "    if not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
        "        continue\n",
        "    print(img_name)\n",
        "    st = time.time()\n",
        "    filepath = os.path.join(test_base_path, img_name)\n",
        "\n",
        "    img = cv2.imread(filepath)\n",
        "\n",
        "    X, ratio = format_img(img, C)\n",
        "    \n",
        "    X = np.transpose(X, (0, 2, 3, 1))\n",
        "\n",
        "    # get output layer Y1, Y2 from the RPN and the feature maps F\n",
        "    # Y1: y_rpn_cls\n",
        "    # Y2: y_rpn_regr\n",
        "    # [Y1, Y2, F] = model_rpn.predict(X, workers=4,use_multiprocessing=True)\n",
        "    [Y1, Y2, F] = model_rpn(X)\n",
        "    Y1 = Y1.numpy()\n",
        "    Y2 = Y2.numpy()\n",
        "    F = F.numpy()\n",
        "\n",
        "   \n",
        "\n",
        "    # Get bboxes by applying NMS \n",
        "    # R.shape = (300, 4)\n",
        "    R = rpn_to_roi(Y1, Y2, C, K.image_data_format(), overlap_thresh=0.7)\n",
        "\n",
        "    # convert from (x1,y1,x2,y2) to (x,y,w,h)\n",
        "    R[:, 2] -= R[:, 0]\n",
        "    R[:, 3] -= R[:, 1]\n",
        "\n",
        "    # apply the spatial pyramid pooling to the proposed regions\n",
        "    bboxes = {}\n",
        "    probs = {}\n",
        "    \n",
        "    # print(R.shape[0]+ 1)\n",
        "    for jk in range(R.shape[0]//C.num_rois + 1):\n",
        "    # for jk in range(5):\n",
        "\n",
        "        \n",
        "        \n",
        "        ROIs = np.expand_dims(R[C.num_rois*jk:C.num_rois*(jk+1), :], axis=0)\n",
        "        if ROIs.shape[1] == 0:\n",
        "            break\n",
        "\n",
        "        if jk == R.shape[0]//C.num_rois:\n",
        "            #pad R\n",
        "            curr_shape = ROIs.shape\n",
        "            target_shape = (curr_shape[0],C.num_rois,curr_shape[2])\n",
        "            ROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
        "            ROIs_padded[:, :curr_shape[1], :] = ROIs\n",
        "            ROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
        "            ROIs = ROIs_padded\n",
        "\n",
        "        \n",
        "        # [P_cls, P_regr] = model_classifier_only.predict([F, ROIs], batch_size=64, workers=4,use_multiprocessing=True)\n",
        "        [P_cls, P_regr] = model_classifier_only([F, ROIs])\n",
        "        P_cls = P_cls.numpy()\n",
        "        P_regr = P_regr.numpy()\n",
        "\n",
        "        # Calculate bboxes coordinates on resized image\n",
        "        \n",
        "        for ii in range(P_cls.shape[1]):\n",
        "\n",
        "            # Ignore 'bg' class\n",
        "            if np.max(P_cls[0, ii, :]) < bbox_threshold or np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n",
        "                continue\n",
        "\n",
        "            cls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n",
        "\n",
        "            if cls_name not in bboxes:\n",
        "                bboxes[cls_name] = []\n",
        "                probs[cls_name] = []\n",
        "\n",
        "            (x, y, w, h) = ROIs[0, ii, :]\n",
        "\n",
        "            cls_num = np.argmax(P_cls[0, ii, :])\n",
        "            try:\n",
        "                (tx, ty, tw, th) = P_regr[0, ii, 4*cls_num:4*(cls_num+1)]\n",
        "                tx /= C.classifier_regr_std[0]\n",
        "                ty /= C.classifier_regr_std[1]\n",
        "                tw /= C.classifier_regr_std[2]\n",
        "                th /= C.classifier_regr_std[3]\n",
        "                x, y, w, h = apply_regr(x, y, w, h, tx, ty, tw, th)\n",
        "            except:\n",
        "                pass\n",
        "            bboxes[cls_name].append([C.rpn_stride*x, C.rpn_stride*y, C.rpn_stride*(x+w), C.rpn_stride*(y+h)])\n",
        "            probs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
        "\n",
        "        \n",
        "    \n",
        "\n",
        "    all_dets = []\n",
        "\n",
        "    for key in bboxes:\n",
        "        bbox = np.array(bboxes[key])\n",
        "\n",
        "        new_boxes, new_probs = non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.2)\n",
        "        for jk in range(new_boxes.shape[0]):\n",
        "            (x1, y1, x2, y2) = new_boxes[jk,:]\n",
        "\n",
        "            # Calculate real coordinates on original image\n",
        "            (real_x1, real_y1, real_x2, real_y2) = get_real_coordinates(ratio, x1, y1, x2, y2)\n",
        "\n",
        "            cv2.rectangle(img,(real_x1, real_y1), (real_x2, real_y2), (int(class_to_color[key][0]), int(class_to_color[key][1]), int(class_to_color[key][2])),4)\n",
        "\n",
        "            textLabel = '{}: {}'.format(key,int(100*new_probs[jk]))\n",
        "            all_dets.append((key,100*new_probs[jk]))\n",
        "\n",
        "            (retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,1,1)\n",
        "            textOrg = (real_x1, real_y1-0)\n",
        "\n",
        "            cv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 1)\n",
        "            cv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n",
        "            cv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 0), 1)\n",
        "\n",
        "    print('Elapsed time = {}'.format(time.time() - st))\n",
        "    print(all_dets)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.grid()\n",
        "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PbMC1r8BqC9k"
      },
      "source": [
        "#### Measure mAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HGt9OlDoU4vM"
      },
      "outputs": [],
      "source": [
        "def get_map(pred, gt, f):\n",
        "\tT = {}\n",
        "\tP = {}\n",
        "\tfx, fy = f\n",
        "\n",
        "\tfor bbox in gt:\n",
        "\t\tbbox['bbox_matched'] = False\n",
        "\n",
        "\tpred_probs = np.array([s['prob'] for s in pred])\n",
        "\tbox_idx_sorted_by_prob = np.argsort(pred_probs)[::-1]\n",
        "\n",
        "\tfor box_idx in box_idx_sorted_by_prob:\n",
        "\t\tpred_box = pred[box_idx]\n",
        "\t\tpred_class = pred_box['class']\n",
        "\t\tpred_x1 = pred_box['x1']\n",
        "\t\tpred_x2 = pred_box['x2']\n",
        "\t\tpred_y1 = pred_box['y1']\n",
        "\t\tpred_y2 = pred_box['y2']\n",
        "\t\tpred_prob = pred_box['prob']\n",
        "\t\tif pred_class not in P:\n",
        "\t\t\tP[pred_class] = []\n",
        "\t\t\tT[pred_class] = []\n",
        "\t\tP[pred_class].append(pred_prob)\n",
        "\t\tfound_match = False\n",
        "\n",
        "\t\tfor gt_box in gt:\n",
        "\t\t\tgt_class = gt_box['class']\n",
        "\t\t\tgt_x1 = gt_box['x1']/fx\n",
        "\t\t\tgt_x2 = gt_box['x2']/fx\n",
        "\t\t\tgt_y1 = gt_box['y1']/fy\n",
        "\t\t\tgt_y2 = gt_box['y2']/fy\n",
        "\t\t\tgt_seen = gt_box['bbox_matched']\n",
        "\t\t\tif gt_class != pred_class:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif gt_seen:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tiou_map = iou((pred_x1, pred_y1, pred_x2, pred_y2), (gt_x1, gt_y1, gt_x2, gt_y2))\n",
        "\t\t\tif iou_map >= 0.5:\n",
        "\t\t\t\tfound_match = True\n",
        "\t\t\t\tgt_box['bbox_matched'] = True\n",
        "\t\t\t\tbreak\n",
        "\t\t\telse:\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\tT[pred_class].append(int(found_match))\n",
        "\n",
        "\tfor gt_box in gt:\n",
        "\t\tif not gt_box['bbox_matched']:# and not gt_box['difficult']:\n",
        "\t\t\tif gt_box['class'] not in P:\n",
        "\t\t\t\tP[gt_box['class']] = []\n",
        "\t\t\t\tT[gt_box['class']] = []\n",
        "\n",
        "\t\t\tT[gt_box['class']].append(1)\n",
        "\t\t\tP[gt_box['class']].append(0)\n",
        "\n",
        "\t#import pdb\n",
        "\t#pdb.set_trace()\n",
        "\treturn T, P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7m0J2BiEqLgA"
      },
      "outputs": [],
      "source": [
        "def format_img_map(img, C):\n",
        "\t\"\"\"Format image for mAP. Resize original image to C.im_size (300 in here)\n",
        "\n",
        "\tArgs:\n",
        "\t\timg: cv2 image\n",
        "\t\tC: config\n",
        "\n",
        "\tReturns:\n",
        "\t\timg: Scaled and normalized image with expanding dimension\n",
        "\t\tfx: ratio for width scaling\n",
        "\t\tfy: ratio for height scaling\n",
        "\t\"\"\"\n",
        "\n",
        "\timg_min_side = float(C.im_size)\n",
        "\t(height,width,_) = img.shape\n",
        "\t\n",
        "\tif width <= height:\n",
        "\t\tf = img_min_side/width\n",
        "\t\tnew_height = int(f * height)\n",
        "\t\tnew_width = int(img_min_side)\n",
        "\telse:\n",
        "\t\tf = img_min_side/height\n",
        "\t\tnew_width = int(f * width)\n",
        "\t\tnew_height = int(img_min_side)\n",
        "\tfx = width/float(new_width)\n",
        "\tfy = height/float(new_height)\n",
        "\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "\t# Change image channel from BGR to RGB\n",
        "\timg = img[:, :, (2, 1, 0)]\n",
        "\timg = img.astype(np.float32)\n",
        "\timg[:, :, 0] -= C.img_channel_mean[0]\n",
        "\timg[:, :, 1] -= C.img_channel_mean[1]\n",
        "\timg[:, :, 2] -= C.img_channel_mean[2]\n",
        "\timg /= C.img_scaling_factor\n",
        "\t# Change img shape from (height, width, channel) to (channel, height, width)\n",
        "\timg = np.transpose(img, (2, 0, 1))\n",
        "\t# Expand one dimension at axis 0\n",
        "\t# img shape becames (1, channel, height, width)\n",
        "\timg = np.expand_dims(img, axis=0)\n",
        "\treturn img, fx, fy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "xNUNkonDqOwg",
        "outputId": "74331d3f-0826-4afc-b30b-f6e7088af662"
      },
      "outputs": [],
      "source": [
        "print(class_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "63-8osThqSjE",
        "outputId": "b9f9832c-df03-41f5-c14e-4f6737f5c34f"
      },
      "outputs": [],
      "source": [
        "# This might takes a while to parser the data\n",
        "test_imgs, _, _ = get_data(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35241
        },
        "colab_type": "code",
        "id": "RfNn-rWQsWPs",
        "outputId": "6b6c1072-5754-4c2c-f941-a5402d3bd8ab"
      },
      "outputs": [],
      "source": [
        "T = {}\n",
        "P = {}\n",
        "mAPs = []\n",
        "for idx, img_data in enumerate(test_imgs):\n",
        "    print('{}/{}'.format(idx,len(test_imgs)))\n",
        "    st = time.time()\n",
        "    filepath = img_data['filepath']\n",
        "\n",
        "    img = cv2.imread(filepath)\n",
        "\n",
        "    X, fx, fy = format_img_map(img, C)\n",
        "\n",
        "    # Change X (img) shape from (1, channel, height, width) to (1, height, width, channel)\n",
        "    X = np.transpose(X, (0, 2, 3, 1))\n",
        "\n",
        "    # get the feature maps and output from the RPN\n",
        "    [Y1, Y2, F] = model_rpn.predict(X, workers=4,use_multiprocessing=True)\n",
        "\n",
        "\n",
        "    R = rpn_to_roi(Y1, Y2, C, K.image_data_format(), overlap_thresh=0.7)\n",
        "\n",
        "    # convert from (x1,y1,x2,y2) to (x,y,w,h)\n",
        "    R[:, 2] -= R[:, 0]\n",
        "    R[:, 3] -= R[:, 1]\n",
        "\n",
        "    # apply the spatial pyramid pooling to the proposed regions\n",
        "    bboxes = {}\n",
        "    probs = {}\n",
        "\n",
        "    for jk in range(R.shape[0] // C.num_rois + 1):\n",
        "        ROIs = np.expand_dims(R[C.num_rois * jk:C.num_rois * (jk + 1), :], axis=0)\n",
        "        if ROIs.shape[1] == 0:\n",
        "            break\n",
        "\n",
        "        if jk == R.shape[0] // C.num_rois:\n",
        "            # pad R\n",
        "            curr_shape = ROIs.shape\n",
        "            target_shape = (curr_shape[0], C.num_rois, curr_shape[2])\n",
        "            ROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
        "            ROIs_padded[:, :curr_shape[1], :] = ROIs\n",
        "            ROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
        "            ROIs = ROIs_padded\n",
        "\n",
        "        [P_cls, P_regr] = model_classifier_only.predict([F, ROIs], workers=4, use_multiprocessing=True)\n",
        "\n",
        "        # Calculate all classes' bboxes coordinates on resized image (300, 400)\n",
        "        # Drop 'bg' classes bboxes\n",
        "        for ii in range(P_cls.shape[1]):\n",
        "\n",
        "            # If class name is 'bg', continue\n",
        "            if np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n",
        "                continue\n",
        "\n",
        "            # Get class name\n",
        "            cls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n",
        "\n",
        "            if cls_name not in bboxes:\n",
        "                bboxes[cls_name] = []\n",
        "                probs[cls_name] = []\n",
        "\n",
        "            (x, y, w, h) = ROIs[0, ii, :]\n",
        "\n",
        "            cls_num = np.argmax(P_cls[0, ii, :])\n",
        "            try:\n",
        "                (tx, ty, tw, th) = P_regr[0, ii, 4 * cls_num:4 * (cls_num + 1)]\n",
        "                tx /= C.classifier_regr_std[0]\n",
        "                ty /= C.classifier_regr_std[1]\n",
        "                tw /= C.classifier_regr_std[2]\n",
        "                th /= C.classifier_regr_std[3]\n",
        "                x, y, w, h = roi_helpers.apply_regr(x, y, w, h, tx, ty, tw, th)\n",
        "            except:\n",
        "                pass\n",
        "            bboxes[cls_name].append([16 * x, 16 * y, 16 * (x + w), 16 * (y + h)])\n",
        "            probs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
        "\n",
        "    all_dets = []\n",
        "\n",
        "    for key in bboxes:\n",
        "        bbox = np.array(bboxes[key])\n",
        "\n",
        "        # Apply non-max-suppression on final bboxes to get the output bounding boxe\n",
        "        new_boxes, new_probs = non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.5)\n",
        "        for jk in range(new_boxes.shape[0]):\n",
        "            (x1, y1, x2, y2) = new_boxes[jk, :]\n",
        "            det = {'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'class': key, 'prob': new_probs[jk]}\n",
        "            all_dets.append(det)\n",
        "\n",
        "\n",
        "    print('Elapsed time = {}'.format(time.time() - st))\n",
        "    t, p = get_map(all_dets, img_data['bboxes'], (fx, fy))\n",
        "    for key in t.keys():\n",
        "        if key not in T:\n",
        "            T[key] = []\n",
        "            P[key] = []\n",
        "        T[key].extend(t[key])\n",
        "        P[key].extend(p[key])\n",
        "    all_aps = []\n",
        "    for key in T.keys():\n",
        "        ap = average_precision_score(T[key], P[key])\n",
        "        print('{} AP: {}'.format(key, ap))\n",
        "        all_aps.append(ap)\n",
        "    print('mAP = {}'.format(np.mean(np.array(all_aps))))\n",
        "    mAPs.append(np.mean(np.array(all_aps)))\n",
        "    #print(T)\n",
        "    #print(P)\n",
        "    \n",
        "print()\n",
        "print('mean average precision:', np.mean(np.array(mAPs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oVBClYzBZtZV"
      },
      "outputs": [],
      "source": [
        "mAP = [mAP for mAP in mAPs if str(mAP)!='nan']\n",
        "mean_average_prec = round(np.mean(np.array(mAP)), 3)\n",
        "print('After training %dk batches, the mean average precision is %0.3f'%(len(record_df), mean_average_prec))\n",
        "\n",
        "# record_df.loc[len(record_df)-1, 'mAP'] = mean_average_prec\n",
        "# record_df.to_csv(C.record_path, index=0)\n",
        "# print('Save mAP to {}'.format(C.record_path))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "frcnn_test_vgg.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
